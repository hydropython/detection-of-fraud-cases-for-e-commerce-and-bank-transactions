{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9754781,"sourceType":"datasetVersion","datasetId":5972728}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-29T13:59:03.087469Z","iopub.execute_input":"2024-10-29T13:59:03.087984Z","iopub.status.idle":"2024-10-29T13:59:04.091609Z","shell.execute_reply.started":"2024-10-29T13:59:03.087933Z","shell.execute_reply":"2024-10-29T13:59:04.090661Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/fruaddfdata/balanced_fraud_df.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install mlflow\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:59:25.447121Z","iopub.execute_input":"2024-10-29T13:59:25.448081Z","iopub.status.idle":"2024-10-29T13:59:43.868889Z","shell.execute_reply.started":"2024-10-29T13:59:25.448041Z","shell.execute_reply":"2024-10-29T13:59:43.867908Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting mlflow\n  Downloading mlflow-2.17.1-py3-none-any.whl.metadata (29 kB)\nCollecting mlflow-skinny==2.17.1 (from mlflow)\n  Downloading mlflow_skinny-2.17.1-py3-none-any.whl.metadata (30 kB)\nRequirement already satisfied: Flask<4 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.0.3)\nRequirement already satisfied: alembic!=1.10.0,<2 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.13.3)\nRequirement already satisfied: docker<8,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (7.1.0)\nCollecting graphene<4 (from mlflow)\n  Downloading graphene-3.4.1-py2.py3-none-any.whl.metadata (6.9 kB)\nRequirement already satisfied: markdown<4,>=3.3 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.6)\nRequirement already satisfied: matplotlib<4 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.7.5)\nRequirement already satisfied: numpy<3 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.26.4)\nRequirement already satisfied: pandas<3 in /opt/conda/lib/python3.10/site-packages (from mlflow) (2.2.2)\nRequirement already satisfied: pyarrow<18,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (16.1.0)\nRequirement already satisfied: scikit-learn<2 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.2.2)\nRequirement already satisfied: scipy<2 in /opt/conda/lib/python3.10/site-packages (from mlflow) (1.14.1)\nRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from mlflow) (2.0.30)\nRequirement already satisfied: Jinja2<4,>=2.11 in /opt/conda/lib/python3.10/site-packages (from mlflow) (3.1.4)\nCollecting gunicorn<24 (from mlflow)\n  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\nCollecting cachetools<6,>=5.0.0 (from mlflow-skinny==2.17.1->mlflow)\n  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\nRequirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==2.17.1->mlflow) (8.1.7)\nRequirement already satisfied: cloudpickle<4 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==2.17.1->mlflow) (3.0.0)\nCollecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.17.1->mlflow)\n  Downloading databricks_sdk-0.36.0-py3-none-any.whl.metadata (38 kB)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==2.17.1->mlflow) (3.1.43)\nRequirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==2.17.1->mlflow) (7.0.0)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==2.17.1->mlflow) (1.25.0)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==2.17.1->mlflow) (1.25.0)\nRequirement already satisfied: packaging<25 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==2.17.1->mlflow) (21.3)\nRequirement already satisfied: protobuf<6,>=3.12.0 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==2.17.1->mlflow) (3.20.3)\nRequirement already satisfied: pyyaml<7,>=5.1 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==2.17.1->mlflow) (6.0.2)\nRequirement already satisfied: requests<3,>=2.17.3 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==2.17.1->mlflow) (2.32.3)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==2.17.1->mlflow) (0.5.0)\nRequirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.5)\nRequirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow) (4.12.2)\nRequirement already satisfied: urllib3>=1.26.0 in /opt/conda/lib/python3.10/site-packages (from docker<8,>=4.0.0->mlflow) (1.26.18)\nRequirement already satisfied: Werkzeug>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow) (3.0.4)\nRequirement already satisfied: itsdangerous>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow) (2.2.0)\nRequirement already satisfied: blinker>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow) (1.8.2)\nCollecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n  Downloading graphql_core-3.2.5-py3-none-any.whl.metadata (10 kB)\nCollecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: python-dateutil<3,>=2.7.0 in /opt/conda/lib/python3.10/site-packages (from graphene<4->mlflow) (2.9.0.post0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2<4,>=2.11->mlflow) (2.1.5)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (10.3.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow) (3.1.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3->mlflow) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<3->mlflow) (2024.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (3.5.0)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.3)\nRequirement already satisfied: google-auth~=2.0 in /opt/conda/lib/python3.10/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.1->mlflow) (2.30.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.17.1->mlflow) (4.0.11)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.17.1->mlflow) (3.19.2)\nRequirement already satisfied: deprecated>=1.2.6 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.1->mlflow) (1.2.14)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.17.1->mlflow) (0.46b0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.1->mlflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.1->mlflow) (3.7)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.1->mlflow) (2024.8.30)\nRequirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.1->mlflow) (1.16.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.17.1->mlflow) (5.0.1)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.1->mlflow) (0.4.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.1->mlflow) (4.9)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.1->mlflow) (0.6.0)\nDownloading mlflow-2.17.1-py3-none-any.whl (26.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading mlflow_skinny-2.17.1-py3-none-any.whl (5.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading graphene-3.4.1-py2.py3-none-any.whl (114 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.7/114.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\nDownloading databricks_sdk-0.36.0-py3-none-any.whl (569 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m569.1/569.1 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading graphql_core-3.2.5-py3-none-any.whl (203 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\nInstalling collected packages: graphql-core, cachetools, gunicorn, graphql-relay, graphene, databricks-sdk, mlflow-skinny, mlflow\n  Attempting uninstall: cachetools\n    Found existing installation: cachetools 4.2.4\n    Uninstalling cachetools-4.2.4:\n      Successfully uninstalled cachetools-4.2.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.8.3 requires cubinlinker, which is not installed.\ncudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.8.3 requires ptxcompiler, which is not installed.\ncuml 24.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.8.3 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\ndataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.9.2 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed cachetools-5.3.3 databricks-sdk-0.36.0 graphene-3.4.1 graphql-core-3.2.5 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-2.17.1 mlflow-skinny-2.17.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv1D, Flatten, SimpleRNN, LSTM, Dropout, Input\nfrom tensorflow.keras.utils import to_categorical\nimport shap  # For model interpretability\nimport mlflow  # For experiment tracking\nimport mlflow.keras  # To log Keras models with MLflow\nimport logging  # For logging\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n\nclass ModelEvaluator:\n    def __init__(self, data_path, target_column, scale_data=True):\n        self.data = pd.read_csv(data_path)\n        self.target_column = target_column\n        self.scale_data = scale_data\n        self.results = {}  # To store model evaluation results\n        self.prepare_data()\n\n    def prepare_data(self):\n        X = self.data.drop(columns=[self.target_column])\n        y = self.data[self.target_column]\n\n        # Convert categorical target to numeric (for classification) if needed\n        if y.dtype == 'O':  # Check if target is categorical\n            y = pd.Categorical(y).codes\n        y = to_categorical(y)  # Convert to one-hot for multi-class classification\n\n        # Handle non-numeric data in features\n        self.handle_non_numeric_data(X)\n        \n        # Scale features if required\n        if self.scale_data:\n            scaler = StandardScaler()\n            X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n\n        # Split into training and test sets\n        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n        \n        # Define input shape based on the training data\n        self.input_shape = (self.X_train.shape[1],)\n\n    def handle_non_numeric_data(self, X):\n        \"\"\"Convert datetime and categorical columns to numeric.\"\"\"\n        for column in X.columns:\n            if X[column].dtype == 'object':\n                if pd.to_datetime(X[column], errors='coerce').notnull().all():\n                    X[column] = pd.to_datetime(X[column])\n                    X[column + '_year'] = X[column].dt.year\n                    X[column + '_month'] = X[column].dt.month\n                    X[column + '_day'] = X[column].dt.day\n                    X.drop(columns=[column], inplace=True)\n                else:\n                    X[column] = X[column].astype('category').cat.codes  # Convert categorical to numeric codes\n\n    def build_mlp(self):\n        model = Sequential([\n            Dense(128, activation='relu', input_shape=self.input_shape),\n            Dense(64, activation='relu'),\n            Dense(self.y_train.shape[1], activation='softmax')\n        ])\n        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n        return model\n\n    def build_cnn(self):\n        model = Sequential([\n            Input(shape=(self.input_shape[0], 1)),\n            Conv1D(64, kernel_size=3, activation='relu'),\n            Flatten(),\n            Dense(self.y_train.shape[1], activation='softmax')\n        ])\n        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n        return model\n\n    def build_rnn(self):\n        model = Sequential([\n            Input(shape=(self.input_shape[0], 1)),\n            SimpleRNN(64, activation='relu'),\n            Dense(self.y_train.shape[1], activation='softmax')\n        ])\n        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n        return model\n\n    def build_lstm(self):\n        model = Sequential([\n            Input(shape=(self.input_shape[0], 1)),\n            LSTM(64, activation='relu'),\n            Dense(self.y_train.shape[1], activation='softmax')\n        ])\n        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n        return model\n\n    def train_model(self, model, model_name):\n        logging.info(f\"Training model: {model_name}\")\n\n        # Reshape data for CNN/RNN/LSTM models\n        if 'CNN' in model_name or 'RNN' in model_name or 'LSTM' in model_name:\n            X_train_reshaped = np.expand_dims(self.X_train.values, axis=2)\n            X_test_reshaped = np.expand_dims(self.X_test.values, axis=2)\n        else:\n            X_train_reshaped = self.X_train.values\n            X_test_reshaped = self.X_test.values\n\n        with mlflow.start_run(run_name=model_name):\n            history = model.fit(X_train_reshaped, self.y_train, validation_data=(X_test_reshaped, self.y_test),\n                                epochs=20, batch_size=32, verbose=1)\n\n            mlflow.keras.log_model(model, model_name)\n            mlflow.log_params({\"optimizer\": \"adam\", \"loss\": \"categorical_crossentropy\", \"epochs\": 10, \"batch_size\": 32})\n            for epoch, accuracy in enumerate(history.history['accuracy']):\n                mlflow.log_metric(f\"train_accuracy_epoch_{epoch+1}\", accuracy)\n            for epoch, val_accuracy in enumerate(history.history['val_accuracy']):\n                mlflow.log_metric(f\"val_accuracy_epoch_{epoch+1}\", val_accuracy)\n\n        return model\n\n    def evaluate_model(self, model, model_name):\n        logging.info(f\"Evaluating model: {model_name}\")\n        \n        y_pred = np.argmax(model.predict(self.X_test.values), axis=1)\n        y_true = np.argmax(self.y_test, axis=1)\n\n        accuracy = accuracy_score(y_true, y_pred)\n        precision = precision_score(y_true, y_pred, average='weighted')\n        recall = recall_score(y_true, y_pred, average='weighted')\n        f1 = f1_score(y_true, y_pred, average='weighted')\n\n        self.results[model_name] = {\n            'accuracy': accuracy,\n            'precision': precision,\n            'recall': recall,\n            'f1_score': f1\n        }\n\n        mlflow.log_metric(\"accuracy\", accuracy)\n        mlflow.log_metric(\"precision\", precision)\n        mlflow.log_metric(\"recall\", recall)\n        mlflow.log_metric(\"f1_score\", f1)\n        logging.info(f\"Model evaluation completed for {model_name}\")\n\n    def explain_model(self, model, model_name):\n        logging.info(f\"Explaining model: {model_name}\")\n        \n        # Configure SHAP kernel explainer for interpretability\n        explainer = shap.KernelExplainer(model.predict, self.X_test.values[:100])\n        shap_values = explainer.shap_values(self.X_test.values[:100])\n\n        # Generate SHAP summary plot and save it as PNG\n        plt.figure()\n        shap.summary_plot(shap_values, self.X_test.values[:100], plot_type=\"bar\", show=False)\n        \n        # Create directory if it doesn't exist\n        if not os.path.exists(\"explainability_plots\"):\n            os.makedirs(\"explainability_plots\")\n        \n        # Save the plot\n        plot_path = f\"explainability_plots/{model_name}_explainability.png\"\n        plt.savefig(plot_path)\n        plt.close()  # Close plot to avoid displaying in the notebook directly\n        \n        logging.info(f\"Explainability summary for {model_name} saved at {plot_path}\")\n    def show_results(self):\n        \"\"\"Displays the evaluation metrics for each model in a readable format.\"\"\"\n        if not self.results:\n            logging.info(\"No results to display. Please run evaluate_model() first.\")\n            return\n\n        print(f\"{'Model Name':<10} {'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1 Score':<10}\")\n        print(\"-\" * 60)\n\n        for model_name, metrics in self.results.items():\n            print(f\"{model_name:<10} {metrics['accuracy']:<10.4f} {metrics['precision']:<10.4f} \"\n                  f\"{metrics['recall']:<10.4f} {metrics['f1_score']:<10.4f}\")\n\n        print(\"\\n\" + \"-\" * 60 + \"\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:59:49.932941Z","iopub.execute_input":"2024-10-29T13:59:49.933308Z","iopub.status.idle":"2024-10-29T14:00:08.151123Z","shell.execute_reply.started":"2024-10-29T13:59:49.933277Z","shell.execute_reply":"2024-10-29T14:00:08.150322Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Step 1: Initialize the evaluator\nevaluator = ModelEvaluator(data_path='/kaggle/input/fruaddfdata/balanced_fraud_df.csv', target_column='class')\n\n# Step 2: Prepare the data\nevaluator.prepare_data()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T14:00:23.260679Z","iopub.execute_input":"2024-10-29T14:00:23.261647Z","iopub.status.idle":"2024-10-29T14:00:26.419624Z","shell.execute_reply.started":"2024-10-29T14:00:23.261586Z","shell.execute_reply":"2024-10-29T14:00:26.418652Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\nCould not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\nCould not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\nCould not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\nCould not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\nCould not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\nCould not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\nCould not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\nCould not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\nCould not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Step 3: Build and train models\nmlp_model = evaluator.build_mlp()\ncnn_model = evaluator.build_cnn()\nrnn_model = evaluator.build_rnn()\nlstm_model = evaluator.build_lstm()","metadata":{"execution":{"iopub.status.busy":"2024-10-29T14:00:46.107777Z","iopub.execute_input":"2024-10-29T14:00:46.108180Z","iopub.status.idle":"2024-10-29T14:00:47.230819Z","shell.execute_reply.started":"2024-10-29T14:00:46.108144Z","shell.execute_reply":"2024-10-29T14:00:47.230027Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluator.train_model(mlp_model, model_name='MLP')\nevaluator.train_model(cnn_model, model_name='CNN')\nevaluator.train_model(rnn_model, model_name='RNN')\nevaluator.train_model(lstm_model, model_name='LSTM')","metadata":{"execution":{"iopub.status.busy":"2024-10-29T14:00:56.604305Z","iopub.execute_input":"2024-10-29T14:00:56.604699Z","iopub.status.idle":"2024-10-29T14:03:46.568806Z","shell.execute_reply.started":"2024-10-29T14:00:56.604663Z","shell.execute_reply":"2024-10-29T14:03:46.567932Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1730210457.642578     140 service.cc:145] XLA service 0x58bf098b1bd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1730210457.642632     140 service.cc:153]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m108/708\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6550 - loss: 0.6187","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1730210458.562862     140 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7167 - loss: 0.5460 - val_accuracy: 0.7485 - val_loss: 0.4932\nEpoch 2/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7586 - loss: 0.4804 - val_accuracy: 0.7533 - val_loss: 0.4843\nEpoch 3/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7666 - loss: 0.4666 - val_accuracy: 0.7542 - val_loss: 0.4798\nEpoch 4/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7709 - loss: 0.4583 - val_accuracy: 0.7584 - val_loss: 0.4765\nEpoch 5/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7649 - loss: 0.4610 - val_accuracy: 0.7577 - val_loss: 0.4762\nEpoch 6/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7717 - loss: 0.4524 - val_accuracy: 0.7564 - val_loss: 0.4817\nEpoch 7/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7654 - loss: 0.4592 - val_accuracy: 0.7582 - val_loss: 0.4784\nEpoch 8/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7728 - loss: 0.4503 - val_accuracy: 0.7556 - val_loss: 0.4808\nEpoch 9/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7742 - loss: 0.4465 - val_accuracy: 0.7552 - val_loss: 0.4817\nEpoch 10/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7724 - loss: 0.4477 - val_accuracy: 0.7517 - val_loss: 0.4883\nEpoch 11/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7774 - loss: 0.4404 - val_accuracy: 0.7519 - val_loss: 0.4833\nEpoch 12/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7765 - loss: 0.4403 - val_accuracy: 0.7513 - val_loss: 0.4932\nEpoch 13/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7740 - loss: 0.4405 - val_accuracy: 0.7504 - val_loss: 0.4928\nEpoch 14/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7824 - loss: 0.4314 - val_accuracy: 0.7522 - val_loss: 0.4911\nEpoch 15/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7819 - loss: 0.4283 - val_accuracy: 0.7538 - val_loss: 0.4940\nEpoch 16/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7769 - loss: 0.4329 - val_accuracy: 0.7536 - val_loss: 0.5046\nEpoch 17/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7850 - loss: 0.4218 - val_accuracy: 0.7464 - val_loss: 0.4987\nEpoch 18/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7844 - loss: 0.4236 - val_accuracy: 0.7460 - val_loss: 0.5069\nEpoch 19/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7853 - loss: 0.4197 - val_accuracy: 0.7338 - val_loss: 0.5080\nEpoch 20/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7872 - loss: 0.4151 - val_accuracy: 0.7398 - val_loss: 0.5094\n","output_type":"stream"},{"name":"stderr","text":"2024/10/29 14:01:24 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n2024/10/29 14:01:34 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpwn8b28jy/model, flavor: keras). Fall back to return ['keras==3.3.3']. Set logging level to DEBUG to see the full traceback. \n2024/10/29 14:01:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7109 - loss: 0.5503 - val_accuracy: 0.7432 - val_loss: 0.5079\nEpoch 2/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7497 - loss: 0.4957 - val_accuracy: 0.7446 - val_loss: 0.4961\nEpoch 3/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7553 - loss: 0.4860 - val_accuracy: 0.7462 - val_loss: 0.4919\nEpoch 4/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7631 - loss: 0.4733 - val_accuracy: 0.7538 - val_loss: 0.4903\nEpoch 5/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7624 - loss: 0.4729 - val_accuracy: 0.7534 - val_loss: 0.4830\nEpoch 6/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7640 - loss: 0.4698 - val_accuracy: 0.7570 - val_loss: 0.4814\nEpoch 7/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7669 - loss: 0.4662 - val_accuracy: 0.7545 - val_loss: 0.4786\nEpoch 8/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7644 - loss: 0.4686 - val_accuracy: 0.7570 - val_loss: 0.4753\nEpoch 9/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7667 - loss: 0.4668 - val_accuracy: 0.7586 - val_loss: 0.4765\nEpoch 10/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7678 - loss: 0.4655 - val_accuracy: 0.7577 - val_loss: 0.4761\nEpoch 11/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7676 - loss: 0.4619 - val_accuracy: 0.7605 - val_loss: 0.4780\nEpoch 12/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7654 - loss: 0.4666 - val_accuracy: 0.7587 - val_loss: 0.4738\nEpoch 13/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7689 - loss: 0.4616 - val_accuracy: 0.7593 - val_loss: 0.4740\nEpoch 14/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7737 - loss: 0.4560 - val_accuracy: 0.7586 - val_loss: 0.4740\nEpoch 15/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7683 - loss: 0.4600 - val_accuracy: 0.7591 - val_loss: 0.4736\nEpoch 16/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7664 - loss: 0.4632 - val_accuracy: 0.7596 - val_loss: 0.4761\nEpoch 17/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7699 - loss: 0.4617 - val_accuracy: 0.7589 - val_loss: 0.4740\nEpoch 18/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7667 - loss: 0.4588 - val_accuracy: 0.7600 - val_loss: 0.4727\nEpoch 19/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7688 - loss: 0.4625 - val_accuracy: 0.7605 - val_loss: 0.4730\nEpoch 20/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7704 - loss: 0.4599 - val_accuracy: 0.7603 - val_loss: 0.4735\n","output_type":"stream"},{"name":"stderr","text":"2024/10/29 14:02:01 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n2024/10/29 14:02:06 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpup8dtac8/model, flavor: keras). Fall back to return ['keras==3.3.3']. Set logging level to DEBUG to see the full traceback. \n2024/10/29 14:02:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7439 - loss: 0.5155 - val_accuracy: 0.7534 - val_loss: 0.4879\nEpoch 2/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7634 - loss: 0.4722 - val_accuracy: 0.7534 - val_loss: 0.4815\nEpoch 3/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7662 - loss: 0.4675 - val_accuracy: 0.7563 - val_loss: 0.4823\nEpoch 4/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7678 - loss: 0.4656 - val_accuracy: 0.7575 - val_loss: 0.4748\nEpoch 5/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7620 - loss: 0.4720 - val_accuracy: 0.7584 - val_loss: 0.4748\nEpoch 6/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7690 - loss: 0.4630 - val_accuracy: 0.7587 - val_loss: 0.4734\nEpoch 7/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7699 - loss: 0.4585 - val_accuracy: 0.7584 - val_loss: 0.4725\nEpoch 8/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7686 - loss: 0.4618 - val_accuracy: 0.7594 - val_loss: 0.4727\nEpoch 9/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7716 - loss: 0.4581 - val_accuracy: 0.7591 - val_loss: 0.4730\nEpoch 10/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7685 - loss: 0.4610 - val_accuracy: 0.7596 - val_loss: 0.4711\nEpoch 11/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7656 - loss: 0.4624 - val_accuracy: 0.7575 - val_loss: 0.4761\nEpoch 12/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7671 - loss: 0.4620 - val_accuracy: 0.7593 - val_loss: 0.4729\nEpoch 13/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7710 - loss: 0.4576 - val_accuracy: 0.7594 - val_loss: 0.4707\nEpoch 14/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7726 - loss: 0.4566 - val_accuracy: 0.7580 - val_loss: 0.4760\nEpoch 15/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7701 - loss: 0.4564 - val_accuracy: 0.7602 - val_loss: 0.4744\nEpoch 16/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7721 - loss: 0.4555 - val_accuracy: 0.7596 - val_loss: 0.4750\nEpoch 17/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7726 - loss: 0.4571 - val_accuracy: 0.7605 - val_loss: 0.4728\nEpoch 18/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7693 - loss: 0.4562 - val_accuracy: 0.7603 - val_loss: 0.4727\nEpoch 19/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7662 - loss: 0.4601 - val_accuracy: 0.7596 - val_loss: 0.4728\nEpoch 20/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7703 - loss: 0.4540 - val_accuracy: 0.7598 - val_loss: 0.4753\n","output_type":"stream"},{"name":"stderr","text":"2024/10/29 14:02:49 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n2024/10/29 14:02:53 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp85582h6q/model, flavor: keras). Fall back to return ['keras==3.3.3']. Set logging level to DEBUG to see the full traceback. \n2024/10/29 14:02:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7187 - loss: 0.5699 - val_accuracy: 0.7303 - val_loss: 0.5129\nEpoch 2/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7533 - loss: 0.4890 - val_accuracy: 0.7490 - val_loss: 0.4892\nEpoch 3/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7568 - loss: 0.4763 - val_accuracy: 0.7522 - val_loss: 0.4821\nEpoch 4/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7664 - loss: 0.4706 - val_accuracy: 0.7561 - val_loss: 0.4786\nEpoch 5/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7666 - loss: 0.4673 - val_accuracy: 0.7533 - val_loss: 0.4784\nEpoch 6/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7612 - loss: 0.4711 - val_accuracy: 0.7563 - val_loss: 0.4752\nEpoch 7/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7700 - loss: 0.4628 - val_accuracy: 0.7598 - val_loss: 0.4764\nEpoch 8/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7688 - loss: 0.4627 - val_accuracy: 0.7557 - val_loss: 0.4741\nEpoch 9/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7693 - loss: 0.4608 - val_accuracy: 0.7563 - val_loss: 0.4731\nEpoch 10/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7659 - loss: 0.4643 - val_accuracy: 0.7589 - val_loss: 0.4717\nEpoch 11/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7704 - loss: 0.4591 - val_accuracy: 0.7591 - val_loss: 0.4706\nEpoch 12/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7673 - loss: 0.4613 - val_accuracy: 0.7591 - val_loss: 0.4708\nEpoch 13/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7684 - loss: 0.4613 - val_accuracy: 0.7603 - val_loss: 0.4705\nEpoch 14/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7663 - loss: 0.4627 - val_accuracy: 0.7593 - val_loss: 0.4714\nEpoch 15/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7727 - loss: 0.4562 - val_accuracy: 0.7600 - val_loss: 0.4701\nEpoch 16/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7742 - loss: 0.4546 - val_accuracy: 0.7598 - val_loss: 0.4706\nEpoch 17/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7741 - loss: 0.4565 - val_accuracy: 0.7598 - val_loss: 0.4703\nEpoch 18/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7748 - loss: 0.4521 - val_accuracy: 0.7596 - val_loss: 0.4697\nEpoch 19/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7677 - loss: 0.4596 - val_accuracy: 0.7602 - val_loss: 0.4699\nEpoch 20/20\n\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7707 - loss: 0.4580 - val_accuracy: 0.7580 - val_loss: 0.4718\n","output_type":"stream"},{"name":"stderr","text":"2024/10/29 14:03:41 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n2024/10/29 14:03:46 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpqll5ukw2/model, flavor: keras). Fall back to return ['keras==3.3.3']. Set logging level to DEBUG to see the full traceback. \n2024/10/29 14:03:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"<Sequential name=sequential_3, built=True>"},"metadata":{}}]},{"cell_type":"code","source":"# Step 4: Evaluate models\nevaluator.evaluate_model(mlp_model, model_name='MLP')\nevaluator.evaluate_model(cnn_model, model_name='CNN')\nevaluator.evaluate_model(rnn_model, model_name='RNN')\nevaluator.evaluate_model(lstm_model, model_name='LSTM')","metadata":{"execution":{"iopub.status.busy":"2024-10-29T14:03:53.984851Z","iopub.execute_input":"2024-10-29T14:03:53.985252Z","iopub.status.idle":"2024-10-29T14:03:57.039397Z","shell.execute_reply.started":"2024-10-29T14:03:53.985215Z","shell.execute_reply":"2024-10-29T14:03:57.038534Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"# Step 5: Show results\nevaluator.show_results()","metadata":{"execution":{"iopub.status.busy":"2024-10-29T14:04:01.869734Z","iopub.execute_input":"2024-10-29T14:04:01.870146Z","iopub.status.idle":"2024-10-29T14:04:01.875158Z","shell.execute_reply.started":"2024-10-29T14:04:01.870109Z","shell.execute_reply":"2024-10-29T14:04:01.874201Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Model Name Accuracy   Precision  Recall     F1 Score  \n------------------------------------------------------------\nMLP        0.7398     0.7791     0.7398     0.7309    \nCNN        0.7603     0.8346     0.7603     0.7468    \nRNN        0.7598     0.8344     0.7598     0.7462    \nLSTM       0.7580     0.8307     0.7580     0.7445    \n\n------------------------------------------------------------\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Step 5: Explain the Model\nevaluator.explain_model(trained_model, model_name='MLP_Model')","metadata":{"execution":{"iopub.status.busy":"2024-10-29T14:07:22.984724Z","iopub.execute_input":"2024-10-29T14:07:22.985832Z","iopub.status.idle":"2024-10-29T14:07:23.308037Z","shell.execute_reply.started":"2024-10-29T14:07:22.985792Z","shell.execute_reply":"2024-10-29T14:07:23.306707Z"},"trusted":true},"execution_count":9,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Step 5: Explain the Model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m evaluator\u001b[38;5;241m.\u001b[39mexplain_model(\u001b[43mtrained_model\u001b[49m, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLP_Model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'trained_model' is not defined"],"ename":"NameError","evalue":"name 'trained_model' is not defined","output_type":"error"}]}]}